{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "135aef12",
   "metadata": {},
   "source": [
    "# LLM-Lasso Tutorial\n",
    "\n",
    "## 1. Setup Instructions\n",
    "1. Install `LLM-Lasso` as an editable package:\n",
    "    ```\n",
    "    $ pip install -e .\n",
    "    ```\n",
    "    for `pip`, or\n",
    "    ```\n",
    "    $ conda develop .\n",
    "    ```\n",
    "    for `conda`. Note that this requires you to `conda install conda-build`.\n",
    "\n",
    "2. Initialize the `adelie` submodule:\n",
    "    ```\n",
    "    $ git submodule init\n",
    "    $ git submodule update\n",
    "    ```\n",
    "3. Install `adelie` as an editable package (`adelie` is used for solving LASSO with penalty factors).\n",
    "    ```\n",
    "    $ cd adelie-fork\n",
    "    $ pip install -e .\n",
    "    ```\n",
    "    or the equivalent for `conda`.\n",
    "\n",
    "4. Copy the file `sample_constants.py` to `_my_constants.py` and populate relevant API keys.\n",
    "\n",
    "The values from `_my_constants.py` are automatically loaded into `constants.py`.\n",
    "\n",
    "### 1.1 Common issues:\n",
    "Intalling `adelie` as an editable package requires compiling from source, which may come with several issues:\n",
    "- `adelie` requires some C++ libraries, namely `eigen`, `llvm`, and `openmp` (which may be installed as `libomp`). For Unix-based systems, these should be available through your package manager, and releases are also available online.\n",
    "- There may issues with the `eigen` library (and others) not being in the `C_INCLUDE_PATH` and `CPLUS_INCLUDE_PATH`. For this, you need to:\n",
    "    - Find where the `eigen` include directory is on your machine (it should be a directory with subdirectories `Eigen` and `unsupported`). For macOS with `eigen` installed via `homebrew`, this may be in a directory that looks like `/opt/homebrew/Cellar/eigen/3.4.0_1/include/eigen3/`. For linux, this may be `/usr/include/eigen3/` or `/usr/local/include/eigen3/`, for instance.\n",
    "\n",
    "    - Run the following:\n",
    "        ```\n",
    "        $ export C_INCLUDE_PATH=\"the_path_from_the_previous_step:$C_INCLUDE_PATH\"\n",
    "        $ export CPLUS_INCLUDE_PATH=\"the_path_from_the_previous_step:$CPLUS_INCLUDE_PATH\"\n",
    "        ```\n",
    "    You may also have to do this with other libraries, like `libomp`.\n",
    "\n",
    "- If you installed `llvm` via `homebrew` on macOS, make sure you run the following:\n",
    "    ```\n",
    "    $ export LDFLAGS=\"-L/opt/homebrew/opt/llvm/lib\"\n",
    "    $ export CPPFLAGS=\"-I/opt/homebrew/opt/llvm/include\"\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a17c68d",
   "metadata": {},
   "source": [
    "## 2. Includes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "636dfadf-b881-4cdf-856d-15fb48112c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llm_lasso.task_specific_lasso.llm_lasso import run_repeated_llm_lasso_cv, PenaltyType\n",
    "from llm_lasso.task_specific_lasso.plotting import plot_heatmap, plot_llm_lasso_result\n",
    "from llm_lasso.data_splits import read_train_test_splits, read_baseline_splits\n",
    "import numpy as np\n",
    "import warnings\n",
    "import json\n",
    "warnings.filterwarnings(\"ignore\")  # Suppress warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a500bf4-1bbb-4ec9-9e3d-07d14efd3630",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "985fe186-d9c6-4330-9d05-2110d2a8b452",
   "metadata": {},
   "source": [
    "## 3. Small-Scale Classification Example: Diabetes\n",
    "The first 4 steps will be run on the command line, and the remainder of the tutorial will be run using this notebook.\n",
    "### Step 1: Generate Training and Test Splits\n",
    "For evaluation, we consider 50/50 balanced training and test splits generated with different random seeds. As the same splits are used for the LASSO portion of LLM-Lasso and the data-driven baselines, we generate them beforehand.\n",
    "\n",
    "To generate $k$ train/test splits, run the following in the command line from the base directory of this repository:\n",
    "```\n",
    "$ python scripts/small_scale_splits.py \\\n",
    "        --dataset Diabetes \\\n",
    "        --save_dir data/splits/diabetes \\\n",
    "        --n-splits 10\n",
    "```\n",
    "\n",
    "### Step 2: Run Data-Driven Baselines\n",
    "Next, run the baseline feature-selected methods that require access to the training splits, e.g., mutual information.\n",
    "```\n",
    "$ python scripts/run_baselines.py \\\n",
    "        --split-dir data/splits/diabetes \\\n",
    "        --n-splits 10 \\\n",
    "        --save-dir data/baselines/diabetes\n",
    "```\n",
    "\n",
    "### Step 3: Run the LLM-Score Baseline\n",
    "For example:\n",
    "```\n",
    "$ python scripts/llm_score.py \\\n",
    "        --prompt-filename prompts/llm-select/diabetes_prompt.txt \\\n",
    "        --feature_names_path small_scale/data/Diabetes_feature_names.pkl \\\n",
    "        --category Diabetes \\\n",
    "        --wipe \\\n",
    "        --save_dir data/llm-score/diabetes \\\n",
    "        --n-trials 1 \\\n",
    "        --step 1 \\\n",
    "        --model-type gpt-4o \\\n",
    "        --temp 0\n",
    "```\n",
    "\n",
    "### Step 4: Generate LLM-Lasso Penalties\n",
    "Note that there is no RAG setup for the small-scale datasets, so we will not enable RAG in the following script.\n",
    "```\n",
    "$ python scripts/llm_lasso_scores.py \\\n",
    "        --prompt-filename prompts/small_scale_prompts/diabetes_prompt.txt \\\n",
    "        --feature_names_path small_scale/data/Diabetes_feature_names.pkl \\\n",
    "        --category Diabetes \\\n",
    "        --wipe \\\n",
    "        --save_dir data/llm-lasso/diabetes \\\n",
    "        --n-trials 1 \\\n",
    "        --model-type gpt-4o \\\n",
    "        --temp 0\n",
    "```\n",
    "\n",
    "### Step 5: Run LLM-Regularized LASSO\n",
    "First, load in the required data splits, penalty factors, and baseline-selected features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4d032fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in splits\n",
    "N_SPLITS = 10\n",
    "x_train, x_test, y_train, y_test = read_train_test_splits(\"../data/splits/diabetes\", N_SPLITS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b39f0ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in LLM-Lasso Penalties\n",
    "penalty_list={\n",
    "    \"plain\": np.array(\n",
    "        np.load(\"../data/llm-lasso/diabetes/final_scores_plain.pkl\", allow_pickle=True)\n",
    "    ),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcb233db-a02b-4aac-8221-ae8eec02dc15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in baseline features\n",
    "feature_baseline = read_baseline_splits(\"../data/baselines/diabetes\", n_splits=N_SPLITS, n_features=len(x_train[0].columns))\n",
    "\n",
    "with open(\"../data/llm-score/diabetes/llmselect_selected_features.json\", \"r\") as f:\n",
    "    llm_select_genes = json.load(f)[f\"{len(x_train[0].columns)}\"]\n",
    "\n",
    "feature_baseline[\"llm_score\"] = [llm_select_genes] * N_SPLITS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "768b66d5",
   "metadata": {},
   "source": [
    "Next, compute test error and AUROC for LLM-Lasso and the baselines, averaged across the splits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c85a8ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = run_repeated_llm_lasso_cv(\n",
    "    x_train_splits=x_train, x_test_splits=x_test,\n",
    "    y_train_splits=y_train, y_test_splits=y_test,\n",
    "    scores=penalty_list,\n",
    "    feature_baseline=feature_baseline,\n",
    "    n_splits=N_SPLITS,\n",
    "    folds_cv=10,\n",
    "    score_type = PenaltyType.PF,\n",
    "    lambda_min_ratio=0.001,\n",
    "    n_threads=8,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c822b243",
   "metadata": {},
   "source": [
    "Plot the test error and AUROC using the dataframe returned by `run_repeated_llm_lasso_cv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdb3f277",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_llm_lasso_result(\n",
    "    res,\n",
    "    bolded_methods=[\"1/imp - plain\"],\n",
    "    plot_error_bars=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02c03189",
   "metadata": {},
   "source": [
    "You can also plot a feature inclusion heatmap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30c6d615",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_heatmap(\n",
    "    res,\n",
    "    method_models=[\"1/imp - plain\", \"Lasso\"], # these are from the method_model column of the dataframe\n",
    "    labels=[\"LLM-Lasso\", \"Lasso\"], # this is how each method_model will be labeled on the plot\n",
    "    feature_names=x_train[0].columns,\n",
    "    sort_by=\"LLM-Lasso\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1722ba4b",
   "metadata": {},
   "source": [
    "## 4. Small-Scale Regression Example: Spotify\n",
    "The first 4 steps will be run on the command line, and the remainder of the tutorial will be run using this notebook.\n",
    "### Command-Line Component\n",
    "Here are the commands to save data splits, run baselines, and generate penalties, same as for the Diabetes example:\n",
    "```\n",
    "$ python scripts/small_scale_splits.py \\\n",
    "        --dataset Spotify \\\n",
    "        --save_dir data/splits/spotify \\\n",
    "        --n-splits 10\n",
    "\n",
    "$ python scripts/run_baselines.py \\\n",
    "        --split-dir data/splits/spotify \\\n",
    "        --n-splits 10 \\\n",
    "        --save-dir data/baselines/spotify\n",
    "\n",
    "$ python scripts/llm_score.py \\\n",
    "        --prompt-filename prompts/llm-select/spotify_prompt.txt \\\n",
    "        --feature_names_path small_scale/data/Spotify_feature_names.pkl \\\n",
    "        --category \"number of Spotify streams\" \\\n",
    "        --wipe \\\n",
    "        --save_dir data/llm-score/spotify \\\n",
    "        --n-trials 1 \\\n",
    "        --step 1 \\\n",
    "        --model-type gpt-4o \\\n",
    "        --temp 0\n",
    "\n",
    "$ python scripts/llm_lasso_scores.py \\\n",
    "        --prompt-filename prompts/small_scale_prompts/spotify_prompt.txt \\\n",
    "        --feature_names_path small_scale/data/Spotify_feature_names.pkl \\\n",
    "        --category \"number of Spotify streams\" \\\n",
    "        --wipe \\\n",
    "        --save_dir data/llm-lasso/spotify \\\n",
    "        --n-trials 1 \\\n",
    "        --model-type gpt-4o \\\n",
    "        --temp 0\n",
    "```\n",
    "\n",
    "### LLM-Regularized LASSO\n",
    "First, load in the required data splits, penalty factors, and baseline-selected features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05217011",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in splits\n",
    "N_SPLITS = 10\n",
    "x_train, x_test, y_train, y_test = read_train_test_splits(\"../data/splits/spotify\", N_SPLITS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a919914d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in LLM-Lasso Penalties\n",
    "penalty_list={\n",
    "    \"plain\": np.array(\n",
    "        np.load(\"../data/llm-lasso/spotify/final_scores_plain.pkl\", allow_pickle=True)\n",
    "    ),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d32c682",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in baseline features\n",
    "feature_baseline = read_baseline_splits(\"../data/baselines/spotify\", n_splits=N_SPLITS, n_features=len(x_train[0].columns))\n",
    "\n",
    "with open(\"../data/llm-score/spotify/llmselect_selected_features.json\", \"r\") as f:\n",
    "    llm_select_genes = json.load(f)[f\"{len(x_train[0].columns)}\"]\n",
    "\n",
    "feature_baseline[\"llm_score\"] = [llm_select_genes] * N_SPLITS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c5dc30f",
   "metadata": {},
   "source": [
    "Ccompute test error and AUROC for LLM-Lasso and the baselines, averaged across the splits.\n",
    "\n",
    "Make sure to pass in **`regression=True`**!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81d4cdef",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = run_repeated_llm_lasso_cv(\n",
    "    x_train_splits=x_train, x_test_splits=x_test,\n",
    "    y_train_splits=y_train, y_test_splits=y_test,\n",
    "    scores=penalty_list,\n",
    "    feature_baseline=feature_baseline,\n",
    "    n_splits=N_SPLITS,\n",
    "    regression=True,\n",
    "    folds_cv=10,\n",
    "    score_type = PenaltyType.PF,\n",
    "    lambda_min_ratio=0.001,\n",
    "    n_threads=8,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d038e98",
   "metadata": {},
   "source": [
    "Plot the test error and AUROC using the dataframe returned by `run_repeated_llm_lasso_cv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "559d35b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_llm_lasso_result(\n",
    "    res,\n",
    "    bolded_methods=[\"1/imp - plain\"],\n",
    "    plot_error_bars=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcce8fd9",
   "metadata": {},
   "source": [
    "Plot the feature inclusion heatmap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f83b5ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_heatmap(\n",
    "    res,\n",
    "    method_models=[\"1/imp - plain\", \"Lasso\"], # these are from the method_model column of the dataframe\n",
    "    labels=[\"LLM-Lasso\", \"Lasso\"], # this is how each method_model will be labeled on the plot\n",
    "    feature_names=x_train[0].columns,\n",
    "    sort_by=\"LLM-Lasso\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f72b76ef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-lasso",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
